{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed27fe3c",
   "metadata": {},
   "source": [
    "# Analise de censo com rede neural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f0ab77a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e2ec95a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Censo.pkl', 'rb') as f:\n",
    "    X_Censo_treinamento, y_censo_treinamento, X_censo_teste, y_censo_teste = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "66ecb6ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((27676, 108), (27676,))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " X_Censo_treinamento.shape, y_censo_treinamento.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6b1282e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4885, 108), (4885,))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " X_censo_teste.shape, y_censo_teste.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dbef45d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.51055982\n",
      "Iteration 2, loss = 0.36082938\n",
      "Iteration 3, loss = 0.34189533\n",
      "Iteration 4, loss = 0.33289795\n",
      "Iteration 5, loss = 0.32703662\n",
      "Iteration 6, loss = 0.32261489\n",
      "Iteration 7, loss = 0.31921979\n",
      "Iteration 8, loss = 0.31648967\n",
      "Iteration 9, loss = 0.31381639\n",
      "Iteration 10, loss = 0.31172776\n",
      "Iteration 11, loss = 0.31044765\n",
      "Iteration 12, loss = 0.30838775\n",
      "Iteration 13, loss = 0.30755744\n",
      "Iteration 14, loss = 0.30638618\n",
      "Iteration 15, loss = 0.30540968\n",
      "Iteration 16, loss = 0.30456868\n",
      "Iteration 17, loss = 0.30427076\n",
      "Iteration 18, loss = 0.30331402\n",
      "Iteration 19, loss = 0.30305672\n",
      "Iteration 20, loss = 0.30254365\n",
      "Iteration 21, loss = 0.30233400\n",
      "Iteration 22, loss = 0.30180683\n",
      "Iteration 23, loss = 0.30116268\n",
      "Iteration 24, loss = 0.30127132\n",
      "Iteration 25, loss = 0.30096916\n",
      "Iteration 26, loss = 0.30058427\n",
      "Iteration 27, loss = 0.30032522\n",
      "Iteration 28, loss = 0.30007435\n",
      "Iteration 29, loss = 0.29978192\n",
      "Iteration 30, loss = 0.29982755\n",
      "Iteration 31, loss = 0.29958110\n",
      "Iteration 32, loss = 0.29913068\n",
      "Iteration 33, loss = 0.29906552\n",
      "Iteration 34, loss = 0.29862952\n",
      "Iteration 35, loss = 0.29815558\n",
      "Iteration 36, loss = 0.29832192\n",
      "Iteration 37, loss = 0.29808079\n",
      "Iteration 38, loss = 0.29782556\n",
      "Iteration 39, loss = 0.29751825\n",
      "Iteration 40, loss = 0.29751543\n",
      "Iteration 41, loss = 0.29721241\n",
      "Iteration 42, loss = 0.29689013\n",
      "Iteration 43, loss = 0.29687155\n",
      "Iteration 44, loss = 0.29644378\n",
      "Iteration 45, loss = 0.29622728\n",
      "Iteration 46, loss = 0.29586681\n",
      "Iteration 47, loss = 0.29594124\n",
      "Iteration 48, loss = 0.29558996\n",
      "Iteration 49, loss = 0.29534794\n",
      "Iteration 50, loss = 0.29516889\n",
      "Iteration 51, loss = 0.29477645\n",
      "Iteration 52, loss = 0.29479789\n",
      "Iteration 53, loss = 0.29456990\n",
      "Iteration 54, loss = 0.29423790\n",
      "Iteration 55, loss = 0.29455023\n",
      "Iteration 56, loss = 0.29408447\n",
      "Iteration 57, loss = 0.29387447\n",
      "Iteration 58, loss = 0.29361857\n",
      "Iteration 59, loss = 0.29312674\n",
      "Iteration 60, loss = 0.29295915\n",
      "Iteration 61, loss = 0.29277132\n",
      "Iteration 62, loss = 0.29248838\n",
      "Iteration 63, loss = 0.29239410\n",
      "Iteration 64, loss = 0.29262486\n",
      "Iteration 65, loss = 0.29196695\n",
      "Iteration 66, loss = 0.29163432\n",
      "Iteration 67, loss = 0.29160424\n",
      "Iteration 68, loss = 0.29176651\n",
      "Iteration 69, loss = 0.29123860\n",
      "Iteration 70, loss = 0.29164118\n",
      "Iteration 71, loss = 0.29111490\n",
      "Iteration 72, loss = 0.29102321\n",
      "Iteration 73, loss = 0.29116560\n",
      "Iteration 74, loss = 0.29123065\n",
      "Iteration 75, loss = 0.29128952\n",
      "Iteration 76, loss = 0.29072681\n",
      "Iteration 77, loss = 0.29050120\n",
      "Iteration 78, loss = 0.29050705\n",
      "Iteration 79, loss = 0.29054231\n",
      "Iteration 80, loss = 0.29026162\n",
      "Iteration 81, loss = 0.29030600\n",
      "Iteration 82, loss = 0.29010545\n",
      "Iteration 83, loss = 0.29007144\n",
      "Iteration 84, loss = 0.28940273\n",
      "Iteration 85, loss = 0.28952171\n",
      "Iteration 86, loss = 0.28928016\n",
      "Iteration 87, loss = 0.28946127\n",
      "Iteration 88, loss = 0.28933028\n",
      "Iteration 89, loss = 0.28913450\n",
      "Iteration 90, loss = 0.28895311\n",
      "Iteration 91, loss = 0.28870114\n",
      "Iteration 92, loss = 0.28862402\n",
      "Iteration 93, loss = 0.28866444\n",
      "Iteration 94, loss = 0.28835527\n",
      "Iteration 95, loss = 0.28852190\n",
      "Iteration 96, loss = 0.28829879\n",
      "Iteration 97, loss = 0.28825592\n",
      "Iteration 98, loss = 0.28838492\n",
      "Iteration 99, loss = 0.28800405\n",
      "Iteration 100, loss = 0.28830814\n",
      "Iteration 101, loss = 0.28850058\n",
      "Iteration 102, loss = 0.28746429\n",
      "Iteration 103, loss = 0.28760369\n",
      "Iteration 104, loss = 0.28796529\n",
      "Iteration 105, loss = 0.28777659\n",
      "Iteration 106, loss = 0.28755618\n",
      "Iteration 107, loss = 0.28724124\n",
      "Iteration 108, loss = 0.28726017\n",
      "Iteration 109, loss = 0.28680857\n",
      "Iteration 110, loss = 0.28726496\n",
      "Iteration 111, loss = 0.28711768\n",
      "Iteration 112, loss = 0.28737607\n",
      "Iteration 113, loss = 0.28686137\n",
      "Iteration 114, loss = 0.28705415\n",
      "Iteration 115, loss = 0.28689245\n",
      "Iteration 116, loss = 0.28699174\n",
      "Iteration 117, loss = 0.28658860\n",
      "Iteration 118, loss = 0.28665606\n",
      "Iteration 119, loss = 0.28668275\n",
      "Iteration 120, loss = 0.28658032\n",
      "Iteration 121, loss = 0.28610917\n",
      "Iteration 122, loss = 0.28662594\n",
      "Iteration 123, loss = 0.28633458\n",
      "Iteration 124, loss = 0.28606026\n",
      "Iteration 125, loss = 0.28646034\n",
      "Iteration 126, loss = 0.28622291\n",
      "Iteration 127, loss = 0.28617585\n",
      "Iteration 128, loss = 0.28642061\n",
      "Iteration 129, loss = 0.28604732\n",
      "Iteration 130, loss = 0.28626880\n",
      "Iteration 131, loss = 0.28610235\n",
      "Iteration 132, loss = 0.28565087\n",
      "Iteration 133, loss = 0.28597476\n",
      "Iteration 134, loss = 0.28593123\n",
      "Iteration 135, loss = 0.28614644\n",
      "Iteration 136, loss = 0.28606896\n",
      "Iteration 137, loss = 0.28590568\n",
      "Iteration 138, loss = 0.28525501\n",
      "Iteration 139, loss = 0.28567347\n",
      "Iteration 140, loss = 0.28593241\n",
      "Iteration 141, loss = 0.28586772\n",
      "Iteration 142, loss = 0.28554232\n",
      "Iteration 143, loss = 0.28529051\n",
      "Iteration 144, loss = 0.28560216\n",
      "Iteration 145, loss = 0.28530210\n",
      "Iteration 146, loss = 0.28537155\n",
      "Iteration 147, loss = 0.28521566\n",
      "Iteration 148, loss = 0.28537702\n",
      "Iteration 149, loss = 0.28512700\n",
      "Iteration 150, loss = 0.28510751\n",
      "Iteration 151, loss = 0.28512530\n",
      "Iteration 152, loss = 0.28465531\n",
      "Iteration 153, loss = 0.28512949\n",
      "Iteration 154, loss = 0.28490717\n",
      "Iteration 155, loss = 0.28524089\n",
      "Iteration 156, loss = 0.28538872\n",
      "Iteration 157, loss = 0.28485659\n",
      "Iteration 158, loss = 0.28530735\n",
      "Iteration 159, loss = 0.28485738\n",
      "Iteration 160, loss = 0.28485694\n",
      "Iteration 161, loss = 0.28446059\n",
      "Iteration 162, loss = 0.28491011\n",
      "Iteration 163, loss = 0.28468187\n",
      "Iteration 164, loss = 0.28482210\n",
      "Iteration 165, loss = 0.28423872\n",
      "Iteration 166, loss = 0.28503163\n",
      "Iteration 167, loss = 0.28463383\n",
      "Iteration 168, loss = 0.28461991\n",
      "Iteration 169, loss = 0.28405323\n",
      "Iteration 170, loss = 0.28450706\n",
      "Iteration 171, loss = 0.28427238\n",
      "Iteration 172, loss = 0.28387010\n",
      "Iteration 173, loss = 0.28425351\n",
      "Iteration 174, loss = 0.28404892\n",
      "Iteration 175, loss = 0.28412947\n",
      "Iteration 176, loss = 0.28407179\n",
      "Iteration 177, loss = 0.28404451\n",
      "Iteration 178, loss = 0.28388430\n",
      "Iteration 179, loss = 0.28401879\n",
      "Iteration 180, loss = 0.28392955\n",
      "Iteration 181, loss = 0.28391958\n",
      "Iteration 182, loss = 0.28344680\n",
      "Iteration 183, loss = 0.28350252\n",
      "Iteration 184, loss = 0.28357997\n",
      "Iteration 185, loss = 0.28410275\n",
      "Iteration 186, loss = 0.28358238\n",
      "Iteration 187, loss = 0.28362850\n",
      "Iteration 188, loss = 0.28357529\n",
      "Iteration 189, loss = 0.28391651\n",
      "Iteration 190, loss = 0.28346848\n",
      "Iteration 191, loss = 0.28346524\n",
      "Iteration 192, loss = 0.28299779\n",
      "Iteration 193, loss = 0.28347190\n",
      "Iteration 194, loss = 0.28331850\n",
      "Iteration 195, loss = 0.28302703\n",
      "Iteration 196, loss = 0.28328718\n",
      "Iteration 197, loss = 0.28348666\n",
      "Iteration 198, loss = 0.28334781\n",
      "Iteration 199, loss = 0.28321121\n",
      "Iteration 200, loss = 0.28299791\n",
      "Iteration 201, loss = 0.28310749\n",
      "Iteration 202, loss = 0.28317033\n",
      "Iteration 203, loss = 0.28278681\n",
      "Iteration 204, loss = 0.28307661\n",
      "Iteration 205, loss = 0.28271307\n",
      "Iteration 206, loss = 0.28250692\n",
      "Iteration 207, loss = 0.28263472\n",
      "Iteration 208, loss = 0.28309827\n",
      "Iteration 209, loss = 0.28244738\n",
      "Iteration 210, loss = 0.28267692\n",
      "Iteration 211, loss = 0.28280647\n",
      "Iteration 212, loss = 0.28307024\n",
      "Iteration 213, loss = 0.28260998\n",
      "Iteration 214, loss = 0.28246196\n",
      "Iteration 215, loss = 0.28264562\n",
      "Iteration 216, loss = 0.28251964\n",
      "Iteration 217, loss = 0.28240422\n",
      "Iteration 218, loss = 0.28220466\n",
      "Iteration 219, loss = 0.28288655\n",
      "Iteration 220, loss = 0.28209942\n",
      "Iteration 221, loss = 0.28232618\n",
      "Iteration 222, loss = 0.28199188\n",
      "Iteration 223, loss = 0.28240657\n",
      "Iteration 224, loss = 0.28252424\n",
      "Iteration 225, loss = 0.28221501\n",
      "Iteration 226, loss = 0.28195606\n",
      "Iteration 227, loss = 0.28184866\n",
      "Iteration 228, loss = 0.28175861\n",
      "Iteration 229, loss = 0.28183248\n",
      "Iteration 230, loss = 0.28215176\n",
      "Iteration 231, loss = 0.28196843\n",
      "Iteration 232, loss = 0.28205624\n",
      "Iteration 233, loss = 0.28222909\n",
      "Iteration 234, loss = 0.28148804\n",
      "Iteration 235, loss = 0.28181566\n",
      "Iteration 236, loss = 0.28154998\n",
      "Iteration 237, loss = 0.28137458\n",
      "Iteration 238, loss = 0.28177656\n",
      "Iteration 239, loss = 0.28174343\n",
      "Iteration 240, loss = 0.28232294\n",
      "Iteration 241, loss = 0.28130432\n",
      "Iteration 242, loss = 0.28190418\n",
      "Iteration 243, loss = 0.28168961\n",
      "Iteration 244, loss = 0.28128864\n",
      "Iteration 245, loss = 0.28140298\n",
      "Iteration 246, loss = 0.28132591\n",
      "Iteration 247, loss = 0.28109774\n",
      "Iteration 248, loss = 0.28137304\n",
      "Iteration 249, loss = 0.28139929\n",
      "Iteration 250, loss = 0.28096142\n",
      "Iteration 251, loss = 0.28113576\n",
      "Iteration 252, loss = 0.28106294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 253, loss = 0.28095737\n",
      "Iteration 254, loss = 0.28102889\n",
      "Iteration 255, loss = 0.28129238\n",
      "Iteration 256, loss = 0.28114124\n",
      "Iteration 257, loss = 0.28105771\n",
      "Iteration 258, loss = 0.28142119\n",
      "Iteration 259, loss = 0.28106779\n",
      "Iteration 260, loss = 0.28136331\n",
      "Iteration 261, loss = 0.28073898\n",
      "Iteration 262, loss = 0.28086338\n",
      "Iteration 263, loss = 0.28061950\n",
      "Iteration 264, loss = 0.28020100\n",
      "Iteration 265, loss = 0.28062741\n",
      "Iteration 266, loss = 0.28089279\n",
      "Iteration 267, loss = 0.28089592\n",
      "Iteration 268, loss = 0.28024138\n",
      "Iteration 269, loss = 0.28107000\n",
      "Iteration 270, loss = 0.28100741\n",
      "Iteration 271, loss = 0.28087574\n",
      "Iteration 272, loss = 0.28088818\n",
      "Iteration 273, loss = 0.28094952\n",
      "Iteration 274, loss = 0.28044642\n",
      "Iteration 275, loss = 0.28071440\n",
      "Training loss did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(7, 8, 10, 5), max_iter=1000, tol=1e-07,\n",
       "              verbose=True)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neural_network_censo = MLPClassifier(max_iter=1000, tol=0.000000100, hidden_layer_sizes=(7,8,10,5),activation='relu',\n",
    "                                                    solver='adam', verbose=True)\n",
    "neural_network_censo.fit(X_Censo_treinamento, y_censo_treinamento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8a9da7f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' <=50K', ' <=50K', ' <=50K', ..., ' <=50K', ' <=50K', ' >50K'],\n",
       "      dtype='<U6')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "previsao = neural_network_censo.predict(X_censo_teste)\n",
    "previsao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "545d8034",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' <=50K', ' <=50K', ' <=50K', ..., ' <=50K', ' <=50K', ' <=50K'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_censo_teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7df0f84b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.842374616171955"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "accuracy_score(y_censo_teste, previsao)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e6bf2eb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.842374616171955"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from yellowbrick.classifier import ConfusionMatrix\n",
    "cm = ConfusionMatrix(neural_network_censo)\n",
    "cm.fit(X_Censo_treinamento, y_censo_treinamento)\n",
    "cm.score(X_censo_teste, y_censo_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "43c1548d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       <=50K       0.87      0.92      0.90      3693\n",
      "        >50K       0.71      0.59      0.65      1192\n",
      "\n",
      "    accuracy                           0.84      4885\n",
      "   macro avg       0.79      0.76      0.77      4885\n",
      "weighted avg       0.84      0.84      0.84      4885\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_censo_teste, previsao))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57882efd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb2ce93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4576b231",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15d14ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
